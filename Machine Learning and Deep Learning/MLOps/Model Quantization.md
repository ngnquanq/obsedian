
***Head first:*** Hi·ªÉu ƒë∆∞·ª£c c√°i n√†y c·∫ßn nhi·ªÅu ki·∫øn th·ª©c kh√°c nhau nh∆∞: [[floating-point numbers]] ho·∫∑c l√† [[how computer stores number]]

First: https://medium.com/@florian_algo/model-quantization-1-basic-concepts-860547ec6aa9

Second: https://medium.com/@florian_algo/model-quantization-2-uniform-and-non-uniform-quantization-47ca5b5d3ec0

Third: https://blog.gopenai.com/model-quantization-3-timing-and-granularity-a0978c6e58d4


Model Quantization (hay c√≤n g·ªçi l√† l∆∞·ª£ng h√≥a model (m√¨nh d·ªãch n√™n h∆°i ƒëu·ªìi, th√¥ng c·∫£m nha üò¢)). 

Trong Deep Learning th√¨ vi·ªác l∆∞·ª£ng h√≥a l√† m·ªôt kƒ© thu·∫≠t cho ph√©p m√¨nh t·ªëi ∆∞u b·ªô nh·ªõ b·∫±ng c√°ch hy sinh ***1 √≠t kh·∫£ nƒÉng c·ªßa m√¥ h√¨nh***. 

L·∫•y v√≠ d·ª• nh∆∞ l√† c√°i QLoRA, ph∆∞∆°ng ph√°p n√†y ƒë√£ c·∫©n th·∫≠n **l∆∞·ª£ng h√≥a c√°c tham s·ªë v·ªÅ d·∫°ng 4-bit** (l√† t·ª´ m·ªôt model c√≥ 65 t·ª∑ tham s·ªë ch·∫°y tr√™n 1 con GPU v·ªõi t·ªïng b·ªô nh·ªõ c·ªßa model t·ª´ 780GB **sang** d∆∞·ªõi 48GB l∆∞u tr·ªØ m√† kh√¥ng ·∫£nh h∆∞·ªüng qu√° nhi·ªÅu t·ªõi performance c·ªßa m√¥ h√¨nh.)

Ok, n√≥i nhi·ªÅu r·ªìi,

# L∆∞·ª£ng H√≥a l√† g√¨?

