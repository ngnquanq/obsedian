
***Head first:*** Hi·ªÉu ƒë∆∞·ª£c c√°i n√†y c·∫ßn nhi·ªÅu ki·∫øn th·ª©c kh√°c nhau nh∆∞: [[Floating-point numbers]] ho·∫∑c l√† [[how computer stores number]]

Reading List:
- Series 3 blog
	-  https://medium.com/@florian_algo/model-quantization-1-basic-concepts-860547ec6aa9
	-  https://medium.com/@florian_algo/model-quantization-2-uniform-and-non-uniform-quantization-47ca5b5d3ec0
	-  https://blog.gopenai.com/model-quantization-3-timing-and-granularity-a0978c6e58d4
- Hugging Face: https://huggingface.co/docs/optimum/concept_guides/quantization

**<u>TLDR</u>** : <mark style="background: #FFB86CA6;">T·ªêI ∆ØU B·ªò NH·ªö B·∫∞NG C√ÅCH GI·∫¢M BIT L∆ØU TR·ªÆ SANG D·∫†NG T·ªêN √çT B·ªò NH·ªö H∆†N.</mark> 


Model Quantization (hay c√≤n g·ªçi l√† l∆∞·ª£ng h√≥a model (m√¨nh d·ªãch n√™n h∆°i ƒëu·ªìi, th√¥ng c·∫£m nha üò¢)). 

Trong Deep Learning th√¨ vi·ªác l∆∞·ª£ng h√≥a l√† m·ªôt kƒ© thu·∫≠t cho ph√©p m√¨nh t·ªëi ∆∞u b·ªô nh·ªõ b·∫±ng c√°ch hy sinh ***1 √≠t kh·∫£ nƒÉng c·ªßa m√¥ h√¨nh***. 

L·∫•y v√≠ d·ª• nh∆∞ l√† c√°i QLoRA, ph∆∞∆°ng ph√°p n√†y ƒë√£ c·∫©n th·∫≠n **l∆∞·ª£ng h√≥a c√°c tham s·ªë v·ªÅ d·∫°ng 4-bit** (l√† t·ª´ m·ªôt model c√≥ 65 t·ª∑ tham s·ªë ch·∫°y tr√™n 1 con GPU v·ªõi t·ªïng b·ªô nh·ªõ c·ªßa model t·ª´ 780GB **sang** d∆∞·ªõi 48GB l∆∞u tr·ªØ m√† kh√¥ng ·∫£nh h∆∞·ªüng qu√° nhi·ªÅu t·ªõi performance c·ªßa m√¥ h√¨nh.)

Ok, n√≥i nhi·ªÅu r·ªìi,

# L∆∞·ª£ng H√≥a l√† g√¨?

Trong to√°n h·ªçc hay l√† x·ª≠ l√≠ t√≠n hi·ªáu s·ªë, l∆∞·ª£ng h√≥a ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác √°nh x·∫° t·ª´ gi√° tr·ªã ƒë·∫ßu v√†o trong m·ªôt t·∫≠p l·ªõn (th∆∞·ªùng l√† t·∫≠p li√™n t·ª•c, v√≠ d·ª• nh∆∞ l√† t·∫≠p s·ªë th·ª±c) sang m·ªôt t·∫≠p nh·ªè h∆°n (th∆∞·ªùng l√† m·ªôt t·∫≠p h·ªØu h·∫°n c√°c s·ªë ho·∫∑c l√† ph·∫ßn t·ª≠, ho·∫∑c l√† v√¥ h·∫°n nh∆∞ng ƒë·∫øm ƒë∆∞·ª£c), ki·ªÉu ki·ªÉu ph∆∞∆°ng ph√°p r·ªùi r·∫°c h√≥a trong lƒ©nh v·ª±c thu·∫≠t to√°n. 

Trong deep learning th√¨ model quantization th·ª±c ch·∫•t l√† vi·ªác chuy·ªÉn ƒë·ªïi t·ª´ high-precision floating-point numbers trong m·ªôt m·∫°ng neural sang low-precision numbers

**Nh∆∞ v·∫≠y, model quantization b·∫£n ch·∫•t l√† m·ªôt h√†m √°nh x·∫°.**



# Nh·ªØng h∆∞·ªõng ti·∫øp c·∫≠n Model Quantization (Objects for Model Quantization)

C√°ch th·ª©c n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho nhi·ªÅu kh√≠a c·∫°nh kh√°c nhau trong deep learning nh∆∞ l√†: 

- **Tr·ªçng s·ªë (weights)**: L∆∞·ª£ng t·ª≠ h√≥a tr·ªçng s·ªë l√† ph·ªï bi·∫øn nh·∫•t, b·ªüi v√¨ n√≥ **l√†m gi·∫£m k√≠ch th∆∞·ªõc m√¥ h√¨nh, b·ªô nh·ªõ s·ª≠ d·ª•ng**
- **H√†m k√≠ch ho·∫°t (activation)**: Th∆∞·ªùng th√¨ m·∫•y c√°i h√†m k√≠ch ho·∫°t c·∫ßn nhi·ªÅu b·ªô nh·ªõ #why , n√™n l√† v·ªõi vi·ªác m√¨nh l∆∞·ª£ng h√≥a ƒë∆∞·ª£c m·∫•y c√°i h√†m n√†y kh√¥ng ch·ªâ l√†m gi·∫£m b·ªô nh·ªõ l∆∞u tr·ªØ m√† khi k·∫øt h·ª£p n√≥ v·ªõi weight quantization, m√¨nh c√≥ th·ªÉ t·∫≠n d·ª•ng t·ªëi ƒëa t√≠nh to√°n s·ªë nguy√™n ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ªôt c√°i performance c·∫£i thi·ªán h∆°n. 
- **KV cache:** C·∫£i thi·ªán throughput c·ªßa vi·ªác t·∫°o ra m·ªôt chu·ªói d√†i
- **ƒê·∫°o h√†m (Gradients)**: √çt ƒë∆∞·ª£c s·ª≠ d·ª•ng h∆°n, v√¨ n·∫øu s·ª≠ d·ª•ng th√¨ ch·ªâ s·ª≠ d·ª•ng cho qu√° tr√¨nh training, c√≤n trong l√∫c inference th√¨ c√≥ c·∫ßn g√¨ ƒë·ª•ng t·ªõi ƒë·∫°o h√†m ƒë√¢u. V√† do trong m·∫∑c ƒë·ªãnh th√¨ m·∫•y c√°i  ƒë·∫°o h√†m n√†y ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng FP32 (trong pytorch). Do ƒë√≥ m√† vi·ªác m√¨nh quantize n√≥ s·∫Ω l√†m gi·∫£m t√≠nh to√°n. 
