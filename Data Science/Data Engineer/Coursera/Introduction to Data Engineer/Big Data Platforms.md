
# Foundations of Big Data

![[Pasted image 20240423145116.png]]

Big Data is 5V 

![[Pasted image 20240423145133.png]]

# Big Data Processing Tools: Hadoop, HDFS, Hive, and Spark

## Big data processing tools 

![[Pasted image 20240423150003.png]]

# Summary and Highlights 

In this lesson, you have learned:

Big Data refers to the vast amounts of data that is being produced each moment of every day, by people, tools, and machines. The sheer velocity, volume, and variety of data challenged the tools and systems used for conventional data, leading to the emergence of processing tools and platforms designed specifically for Big Data. Big Data processing technologies help derive value from big data. These include NoSQL databases and Data Lakes and open-source technologies such as Apache Hadoop, Apache Hive, and Apache Spark.

- Hadoop provides distributed storage and processing of large datasets across clusters of computers. One of its main components, the Hadoop File Distribution System, or HDFS, is a storage system for big data.
    
- Hive is a data warehouse software for reading, writing, and managing large datasets.
    
- Spark is a general-purpose data processing engine designed to extract and process large volumes of data.

